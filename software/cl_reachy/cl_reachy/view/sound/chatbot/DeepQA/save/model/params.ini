[General]
version = 0.5
globstep = 357000
watsonmode = False
autoencode = False
corpus = cornell

[Dataset]
datasettag = 
maxlength = 10
filtervocab = 1
skiplines = False
vocabularysize = 5000

[Network]
hiddensize = 512
numlayers = 2
softmaxsamples = 0
initembeddings = False
embeddingsize = 64
embeddingsource = GoogleNews-vectors-negative300.bin

[Training (won't be restored)]
learningrate = 0.002
batchsize = 256
dropout = 0.9

